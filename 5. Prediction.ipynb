{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this phase is to combine all previous steps into one file and predict 'delayInSecods' fo the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import xgboost as xgb \n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test file preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set column types to minimize filed size\n",
    "column_types= {'id': 'int32',\n",
    "               'stopId': 'int32',\n",
    "               'routeId': 'int16',\n",
    "               'vehicleId': 'int32',\n",
    "               'tripId': 'int16',\n",
    "               'delayInSeconds': 'int32',\n",
    "               'agencyId': 'int8',\n",
    "               }\n",
    "# create DataFrame\n",
    "df = pd.read_csv('train.csv', dtype=column_types, parse_dates=['delayPredictionTimestamp','scheduleTime'])\n",
    "# merge stopsintrips file.Merge stopSequence on:'routeId','stopId', 'tripId', merge agency ID on route ID only to have minimal number of missing rows\n",
    "#Topology excluced as contains same info as route ID\n",
    "stops=pd.read_csv('stopsintrips.csv', dtype=column_types)\n",
    "stops_1=stops[['routeId','agencyId']].drop_duplicates()\n",
    "df=df.merge(right=stops_1, how='left', on=['routeId'])\n",
    "df=df.merge(right=stops[['routeId', 'stopId', 'stopSequence', 'tripId']], how='left', on=['routeId','stopId', 'tripId'])\n",
    "# merge stops file containig location. Not all locations exist in stops file.\n",
    "location=pd.read_csv('stops.csv', dtype=column_types)\n",
    "missing_location=df[~df['stopId'].isin(location['stopId'])]['stopId'].unique().reshape(-1,1)\n",
    "# as there is linear correlation between location and stopID, missing data to be predicted by LinearRegression model\n",
    "# predict missing stopLat\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X=location.iloc[:,:1].values\n",
    "y=location['stopLat'].values\n",
    "lr_lat=LinearRegression()\n",
    "lr_lat.fit(X,y)\n",
    "# predict missing stopLon\n",
    "X=location.iloc[:,:1].values\n",
    "y=location['stopLon'].values\n",
    "lr_lon=LinearRegression()\n",
    "lr_lon.fit(X,y)\n",
    "# add predicted missing locations to location df\n",
    "missing_lon=lr_lon.predict(missing_location)\n",
    "missing_lat=lr_lat.predict(missing_location)\n",
    "missing_loc_df=pd.DataFrame({'stopId':np.squeeze(missing_location), 'stopLat':missing_lat, 'stopLon':missing_lon})\n",
    "location=pd.concat([location,missing_loc_df],axis=0)\n",
    "# merge locations with df\n",
    "df=df.merge(right=location, how='left', left_on=['stopId'], right_on=['stopId'])\n",
    "# merge weather df. Remove duplicates. Forward fill missing hour rows. Drop columns that do not add value (tested)\n",
    "weather=pd.read_csv('weatherHistory.csv',sep=';')\n",
    "weather['dt']=pd.to_datetime(weather['dt'],unit='s')\n",
    "weather.drop_duplicates(subset='dt', keep='first',inplace=True)\n",
    "weather=weather.set_index(pd.DatetimeIndex(weather['dt']))\n",
    "weather=weather.resample('H').ffill()\n",
    "weather.drop(['dt','dt_iso', 'city_id', 'temp_min', 'temp_max','weather_icon','weather_description','weather_id', 'weather_main', 'pressure', 'clouds_all'], axis=1, inplace=True)\n",
    "cols=['humidity','wind_speed','wind_deg']\n",
    "for col in cols: weather[col]=pd.to_numeric(weather[col], downcast='signed')\n",
    "df['dt']=df['scheduleTime'].dt.round('h')\n",
    "df=df.merge(right=weather, how='left', left_on='dt', right_index=True)\n",
    "df.drop(['dt'], axis=1, inplace=True)\n",
    "# deal with other missing data. AgencyID: fill with most common value '1', stopSequence: fill with median '12'\n",
    "df['agencyId']=df['agencyId'].fillna(1)\n",
    "df['stopSequence']=df['stopSequence'].fillna(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test file preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create test DataFrame\n",
    "test = pd.read_csv('test.csv', dtype=column_types, parse_dates=['delayPredictionTimestamp','scheduleTime'])\n",
    "# merge stopsintrips file\n",
    "test=test.merge(right=stops_1, how='left', on=['routeId'])\n",
    "test=test.merge(right=stops[['routeId', 'stopId', 'stopSequence', 'tripId']], how='left', on=['routeId','stopId', 'tripId'])\n",
    "# find missing stopsID in file with location\n",
    "missing_location=test[~test['stopId'].isin(location['stopId'])]['stopId'].unique().reshape(-1,1)\n",
    "# predict missing location with already trained lr models\n",
    "missing_lon=lr_lon.predict(missing_location)\n",
    "missing_lat=lr_lat.predict(missing_location)\n",
    "missing_loc_df=pd.DataFrame({'stopId':np.squeeze(missing_location), 'stopLat':missing_lat, 'stopLon':missing_lon})\n",
    "location=pd.concat([location,missing_loc_df],axis=0)\n",
    "# merge file with location\n",
    "test=test.merge(right=location, how='left', left_on=['stopId'], right_on=['stopId'])\n",
    "# merge weather file\n",
    "test['dt']=test['scheduleTime'].dt.round('h')\n",
    "test=test.merge(right=weather, how='left', left_on='dt', right_index=True, copy=False)\n",
    "test.drop(['dt'], axis=1, inplace=True)\n",
    "# fill missing data\n",
    "test['agencyId']=test['agencyId'].fillna(1)\n",
    "test['stopSequence']=test['stopSequence'].fillna(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# difference between delayPrediction and schedule time. Wrong date when time close to midnight need to add or subtract 24h\n",
    "df['time_diff']=(df['delayPredictionTimestamp']-df['scheduleTime']).astype('timedelta64[s]')\n",
    "df['time_diff']=pd.to_numeric(df['time_diff'], downcast='signed')\n",
    "df['time_diff']=df['time_diff'].apply(lambda x: x+86400 if x <-50000 else x)\n",
    "df['time_diff']=df['time_diff'].apply(lambda x: x-86400 if x >50000 else x)\n",
    "# time features: hour, dayofweek, time- day time in seconds\n",
    "df['hour'] = df['scheduleTime'].dt.hour\n",
    "df['dayofweek'] = df['scheduleTime'].dt.dayofweek\n",
    "df['time']=df['delayPredictionTimestamp'].dt.second+df['delayPredictionTimestamp'].dt.minute*60+df['delayPredictionTimestamp'].dt.hour*3600\n",
    "# mean delayInSeconds of each agency, routeId, stopID, vehicleId, tripID\n",
    "agencyMeanDelay = df[ ['agencyId', 'delayInSeconds'] ].groupby(['agencyId']).mean().to_dict()['delayInSeconds']\n",
    "df['agencyMeanDelay'] = df['agencyId'].map(lambda x: agencyMeanDelay[x])\n",
    "routeMeanDelay = df[ ['routeId', 'delayInSeconds'] ].groupby(['routeId']).mean().to_dict()['delayInSeconds']\n",
    "df['routeMeanDelay'] = df['routeId'].map(lambda x: routeMeanDelay[x])\n",
    "stopIdMeanDelay = df[ ['stopId', 'delayInSeconds'] ].groupby(['stopId']).mean().to_dict()['delayInSeconds']\n",
    "df['stopIdMeanDelay'] = df['stopId'].map(lambda x: stopIdMeanDelay[x])\n",
    "vehicleIdMeanDelay = df[ ['vehicleId', 'delayInSeconds'] ].groupby(['vehicleId']).mean().to_dict()['delayInSeconds']\n",
    "df['vehicleIdMeanDelay'] = df['vehicleId'].map(lambda x: vehicleIdMeanDelay[x])\n",
    "tripIdMeanDelay = df[ ['tripId', 'delayInSeconds'] ].groupby(['tripId']).mean().to_dict()['delayInSeconds']\n",
    "df['tripIdMeanDelay'] = df['tripId'].map(lambda x: tripIdMeanDelay[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define features function to exclude some columns from features matrix\n",
    "def features(df):\n",
    "    feats = df.columns.values\n",
    "    black_list = ['id', 'delayInSeconds','delayPredictionTimestamp','scheduleTime', 'delayInSeconds_xgb']\n",
    "    return [feat for feat in feats if feat not in black_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopId</th>\n",
       "      <th>routeId</th>\n",
       "      <th>vehicleId</th>\n",
       "      <th>tripId</th>\n",
       "      <th>agencyId</th>\n",
       "      <th>stopSequence</th>\n",
       "      <th>stopLat</th>\n",
       "      <th>stopLon</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>time</th>\n",
       "      <th>agencyMeanDelay</th>\n",
       "      <th>routeMeanDelay</th>\n",
       "      <th>stopIdMeanDelay</th>\n",
       "      <th>vehicleIdMeanDelay</th>\n",
       "      <th>tripIdMeanDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204</td>\n",
       "      <td>11</td>\n",
       "      <td>377</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>54.39919</td>\n",
       "      <td>18.59498</td>\n",
       "      <td>291.15</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>43832</td>\n",
       "      <td>163.450028</td>\n",
       "      <td>153.355873</td>\n",
       "      <td>465.887850</td>\n",
       "      <td>146.086857</td>\n",
       "      <td>171.803197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2051</td>\n",
       "      <td>11</td>\n",
       "      <td>377</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>54.41812</td>\n",
       "      <td>18.57758</td>\n",
       "      <td>291.15</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>-47</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>43153</td>\n",
       "      <td>163.450028</td>\n",
       "      <td>153.355873</td>\n",
       "      <td>114.189903</td>\n",
       "      <td>146.086857</td>\n",
       "      <td>171.803197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2092</td>\n",
       "      <td>11</td>\n",
       "      <td>377</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>54.40425</td>\n",
       "      <td>18.59102</td>\n",
       "      <td>291.15</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>43684</td>\n",
       "      <td>163.450028</td>\n",
       "      <td>153.355873</td>\n",
       "      <td>156.111310</td>\n",
       "      <td>146.086857</td>\n",
       "      <td>171.803197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2094</td>\n",
       "      <td>11</td>\n",
       "      <td>377</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>54.40905</td>\n",
       "      <td>18.58866</td>\n",
       "      <td>291.15</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>43568</td>\n",
       "      <td>163.450028</td>\n",
       "      <td>153.355873</td>\n",
       "      <td>119.286389</td>\n",
       "      <td>146.086857</td>\n",
       "      <td>171.803197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2096</td>\n",
       "      <td>11</td>\n",
       "      <td>377</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>54.41262</td>\n",
       "      <td>18.58775</td>\n",
       "      <td>291.15</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>43521</td>\n",
       "      <td>163.450028</td>\n",
       "      <td>153.355873</td>\n",
       "      <td>79.494773</td>\n",
       "      <td>146.086857</td>\n",
       "      <td>171.803197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stopId  routeId  vehicleId  tripId  agencyId  stopSequence   stopLat  \\\n",
       "0     204       11        377      22       2.0          37.0  54.39919   \n",
       "1    2051       11        377      22       2.0          31.0  54.41812   \n",
       "2    2092       11        377      22       2.0          36.0  54.40425   \n",
       "3    2094       11        377      22       2.0          35.0  54.40905   \n",
       "4    2096       11        377      22       2.0          34.0  54.41262   \n",
       "\n",
       "    stopLon    temp  humidity       ...         wind_deg  time_diff  hour  \\\n",
       "0  18.59498  291.15        59       ...              250         92    12   \n",
       "1  18.57758  291.15        59       ...              250        -47    12   \n",
       "2  18.59102  291.15        59       ...              250         64    12   \n",
       "3  18.58866  291.15        59       ...              250          8    12   \n",
       "4  18.58775  291.15        59       ...              250         21    12   \n",
       "\n",
       "   dayofweek   time  agencyMeanDelay  routeMeanDelay  stopIdMeanDelay  \\\n",
       "0          2  43832       163.450028      153.355873       465.887850   \n",
       "1          2  43153       163.450028      153.355873       114.189903   \n",
       "2          2  43684       163.450028      153.355873       156.111310   \n",
       "3          2  43568       163.450028      153.355873       119.286389   \n",
       "4          2  43521       163.450028      153.355873        79.494773   \n",
       "\n",
       "   vehicleIdMeanDelay  tripIdMeanDelay  \n",
       "0          146.086857       171.803197  \n",
       "1          146.086857       171.803197  \n",
       "2          146.086857       171.803197  \n",
       "3          146.086857       171.803197  \n",
       "4          146.086857       171.803197  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature engineering\n",
    "df[features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would train both XGBoost model and RandomForest one with the best parameters I chose in model tuning phase. Then I'll check predicted 'delayInSeconds' obtained from both models and combination of both models in Kaggle competition and choose the best final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature matrix, labels array creation\n",
    "X=df[features].values\n",
    "y=df['delayInSeconds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train XGBoost model on the best parameters chosen in grid search\n",
    "xgb_model = xgb.XGBRegressor(max_depth=3, learning_rate=0.1, n_estimators=300, random_state=2018, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:37:50] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,\n",
       "       n_jobs=-1, nthread=None, objective='reg:linear', random_state=2018,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "xgb_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train Random Forest model on the best parameters chosen in grid search\n",
    "rf=RandomForestRegressor(max_depth=12, min_samples_leaf=5, n_estimators=50, random_state=2018, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=5, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "           oob_score=False, random_state=2018, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature engineering of test DataFrame\n",
    "# time_diff\n",
    "test['time_diff']=(test['delayPredictionTimestamp']-test['scheduleTime']).astype('timedelta64[s]')\n",
    "test['time_diff']=pd.to_numeric(test['time_diff'], downcast='signed')\n",
    "test['time_diff']=test['time_diff'].apply(lambda x: x+86400 if x <-50000 else x)\n",
    "test['time_diff']=test['time_diff'].apply(lambda x: x-86400 if x >50000 else x)\n",
    "# time features\n",
    "test['hour'] = test['scheduleTime'].dt.hour\n",
    "test['dayofweek'] = test['scheduleTime'].dt.dayofweek\n",
    "test['time']=test['delayPredictionTimestamp'].dt.second+test['delayPredictionTimestamp'].dt.minute*60+test['delayPredictionTimestamp'].dt.hour*3600\n",
    "# mean delayInSec, if no data in mean dictionary, use mean delay of whole training dataset\n",
    "meanDelay=df['delayInSeconds'].mean()\n",
    "test['agencyMeanDelay'] = test['agencyId'].map(lambda x: agencyMeanDelay.get(x,meanDelay))\n",
    "test['routeMeanDelay'] = test['routeId'].map(lambda x: routeMeanDelay.get(x,meanDelay))\n",
    "test['stopIdMeanDelay'] = test['stopId'].map(lambda x: stopIdMeanDelay.get(x,meanDelay))\n",
    "test['vehicleIdMeannDelay'] = test['vehicleId'].map(lambda x: vehicleIdMeanDelay.get(x,meanDelay))\n",
    "test['tripIdMeanDelay'] = test['tripId'].map(lambda x: tripIdMeanDelay.get(x,meanDelay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict delayInSeconds using XGBoost model\n",
    "test['delayInSeconds_xgb']=xgb_model.predict(test[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change predictions to integers\n",
    "test['delayInSeconds_xgb']=test['delayInSeconds_xgb'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict delayInSeconds using Random Forest model\n",
    "test['delayInSeconds_rf']=rf.predict(test[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change predictions to integers\n",
    "test['delayInSeconds_rf']=test['delayInSeconds_rf'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take weighted average from 2 models predictions as final prediction\n",
    "test['delayInSeconds']=0.7*test['delayInSeconds_xgb']+0.3*test['delayInSeconds_rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save prediction file\n",
    "test[['id','delayInSeconds']].to_csv('solution_xgb&rf_final', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested each model separately and the a few combination of both models. I got following results on Kaggle:\n",
    "\n",
    "The combination 70% of values predicted by XGBoost and 30% of values predicted by RandomForest was my best prediction and the one that won the competition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
